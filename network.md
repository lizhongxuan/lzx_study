# 性能优化案例 - 网络

> **导航**：[🔙 返回目录页](./README.md)
---
### 案例一：基于 RSS Hash 的无锁流聚合架构

####   科普的简介

> 针对多线程并发写入全局会话表导致的**锁竞争（Lock Contention）痛点**，我设计了**基于 RSS Hash 的 Share-Nothing 架构**。主要是利用**网卡硬件分流特性进行线程绑定**，确保同一条流只由特定线程处理，彻底移除了流聚合阶段的锁，最终实现了性能随核数线性扩展。

#### 背景

Agent 内部是多线程工作的，多个 Worker 需要更新全局的 FlowMap。如果使用全局锁（Mutex/RwLock），随着核数增加，锁的争抢会呈指数级上升，导致 CPU 大量消耗在 `futex` 等待上，出现“加核不加量”的现象。

#### 实现逻辑

1. **硬分流**：利用网卡 RSS（Receive Side Scaling）特性，或者在软件层计算五元组 Hash。
2. **线程亲和性 (Affinity)**：设计分发路由，保证 `Hash(Flow) % Thread_Num` 结果一致的数据包，永远分发给同一个线程。
3. **数据隔离**：每个线程独享一个局部的 `FlowMap`，内存不共享。
4. **无锁操作**：由于数据归属明确，对流状态的读写完全不需要加锁。

#### 难点

1. **大象流问题**：如果某条流流量极大，会导致单个线程过载。解决方案是引入二级负载检测，识别大象流并特殊标记。
2. **动态扩容**：运行时调整线程数会导致 Hash 映射失效。目前的取舍是容忍扩容瞬间的少量流切分，或采用重启重建策略。

#### 结果

1. 实现了完美的**线性扩展**（Linear Scalability）。
2. 彻底消除了 Profile 图中的锁等待时间，CPU 利用率均为有效计算。

#### 思考

1. **Cache 友好性**：这种方案带来的额外收益是 CPU L1/L2 Cache 命中率极高，因为同一条流的数据一直停留在同一个核心的 Cache 中。
